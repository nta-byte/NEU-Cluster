{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import sklearn\n",
    "import sklearn.cluster\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn.manifold\n",
    "import sklearn.model_selection\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'../')\n",
    "from helper import (classification_tools as ct,\n",
    "                   visualize as vis)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1_path = Path('..','data','features','VGG16_fc1_features_std.pickle')\n",
    "assert fc1_path.is_file()\n",
    "\n",
    "le_path = Path('..','models','label_encoder.pickle')\n",
    "assert le_path.is_file()\n",
    "\n",
    "\n",
    "with open(fc1_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "with open(le_path, 'rb') as f:\n",
    "    le = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = data['filename']\n",
    "fc1 = data['features']\n",
    "labels = data['labels']\n",
    "y_gt = le.transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pca=50\n",
    "pca = PCA(n_components=n_pca, svd_solver='full', whiten=True)\n",
    "pca_nw = PCA(n_components=n_pca, svd_solver='full', whiten=False)\n",
    "x = pca.fit_transform(fc1)\n",
    "x_nw = pca_nw.fit_transform(fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(range(1,n_pca+1), pca_nw.explained_variance_ratio_.cumsum(), '-o')\n",
    "ax.set_xlabel('Number of Components')\n",
    "ax.set_ylabel('Cumulative Variance Explained')\n",
    "ax.grid(which='both')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cache = False\n",
    "kmeans_cross_val_results_cache_path = Path('..','.neu_cache','kmeans_crossval_cache.pickle')\n",
    "\n",
    "if not use_cache or not kmeans_cross_val_results_cache_path.is_file():\n",
    "    rs = np.random.RandomState(seed=2618930764)\n",
    "    n_splits=5\n",
    "    train_acc = np.zeros(n_splits)\n",
    "    val_acc = np.zeros(n_splits)\n",
    "    \n",
    "    kfold = sklearn.model_selection.KFold(n_splits=n_splits, shuffle=True, random_state=rs.randint(2**32))\n",
    "    splits = kfold.split(x)\n",
    "    n_pca=35\n",
    "\n",
    "    for i, (train, test) in enumerate(splits):\n",
    "        \n",
    "        fc1train = fc1[train]\n",
    "        fc1val = fc1[test]\n",
    "\n",
    "        Ytrain = y_gt[train]\n",
    "        Yval = y_gt[test]\n",
    "        \n",
    "        pca_cval = PCA(n_components=n_pca, whiten=True, svd_solver='full')\n",
    "        pca_cval.fit(fc1train)\n",
    "        xtrain_cval = pca_cval.transform(fc1train)\n",
    "        xval_cval = pca_cval.transform(fc1val)\n",
    "        \n",
    "        kmeans = sklearn.cluster.KMeans(n_clusters=7, init='k-means++', n_init=500, random_state=rs.randint(2**32))\n",
    "        kmeans.fit(xtrain_cval)\n",
    "\n",
    "        labels_train = kmeans.labels_\n",
    "        labels_val = kmeans.predict(xval_cval)\n",
    "\n",
    "        Ypred_train = ct.label_matcher(labels_train, Ytrain)\n",
    "        Ypred_val = ct.label_matcher(labels_val, Yval)\n",
    "\n",
    "        train_acc[i] = (Ypred_train == Ytrain).sum()/len(Ytrain)\n",
    "        val_acc[i] = (Ypred_val == Yval).sum()/len(Yval)\n",
    "        \n",
    "    with open(kmeans_cross_val_results_cache_path, 'wb') as f:\n",
    "        pickle.dump({'train_acc': train_acc,\n",
    "                    'val_acc': val_acc,\n",
    "                    'n_pca':n_pca},\n",
    "                   f)\n",
    "else:\n",
    "    with open(kmeans_cross_val_results_cache_path, 'rb') as f:\n",
    "        results_ = pickle.load(f)\n",
    "        train_acc = results_['train_acc']\n",
    "        val_acc = results_['val_acc']\n",
    "        n_pca = results_['n_pca']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('PCA {:>3} components + whitening'.format(n_pca))\n",
    "print('Train Accuracy\\t\\tValidation Accuracy')\n",
    "for i, (trainacc, valacc) in enumerate(zip(train_acc, val_acc)):\n",
    "    print(\"    {:.4f}\\t\\t\\t{:.4f}\".format(trainacc, valacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cache = True\n",
    "\n",
    "kmeans_cross_val_results_cache_path_50c = Path('..','.neu_cache','kmeans_crossval_cache_50c.pickle')\n",
    "\n",
    "if not use_cache or not kmeans_cross_val_results_cache_path_50c.is_file():\n",
    "    rs = np.random.RandomState(seed=3732236083)\n",
    "    n_splits=5\n",
    "    train_acc = np.zeros(n_splits)\n",
    "    val_acc = np.zeros(n_splits)\n",
    "    \n",
    "    kfold = sklearn.model_selection.KFold(n_splits=n_splits, shuffle=True, random_state=rs.randint(2**32))\n",
    "    splits = kfold.split(x)\n",
    "\n",
    "    for i, (train, test) in enumerate(splits):\n",
    "        \n",
    "        fc1train = fc1[train]\n",
    "        fc1val = fc1[test]\n",
    "\n",
    "        Ytrain = y_gt[train]\n",
    "        Yval = y_gt[test]\n",
    "        \n",
    "        pca_cval = PCA(n_components=50, whiten=True, svd_solver='full')\n",
    "        pca_cval.fit(fc1train)\n",
    "        xtrain_cval = pca_cval.transform(fc1train)\n",
    "        xval_cval = pca_cval.transform(fc1val)\n",
    "        \n",
    "        kmeans = sklearn.cluster.KMeans(n_clusters=7, init='k-means++', n_init=500, random_state=rs.randint(2**32))\n",
    "        kmeans.fit(xtrain_cval)\n",
    "\n",
    "        labels_train = kmeans.labels_\n",
    "        labels_val = kmeans.predict(xval_cval)\n",
    "\n",
    "        Ypred_train = ct.label_matcher(labels_train, Ytrain)\n",
    "        Ypred_val = ct.label_matcher(labels_val, Yval)\n",
    "\n",
    "        train_acc[i] = (Ypred_train == Ytrain).sum()/len(Ytrain)\n",
    "        val_acc[i] = (Ypred_val == Yval).sum()/len(Yval)\n",
    "        \n",
    "    with open(kmeans_cross_val_results_cache_path_50c, 'wb') as f:\n",
    "        pickle.dump({'train_acc': train_acc,\n",
    "                    'val_acc': val_acc,\n",
    "                    'n_pca':n_pca},\n",
    "                   f)\n",
    "else:\n",
    "    with open(kmeans_cross_val_results_cache_path_50c, 'rb') as f:\n",
    "        results_ = pickle.load(f)\n",
    "        train_acc = results_['train_acc']\n",
    "        val_acc = results_['val_acc']\n",
    "        n_pca = results_['n_pca']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('PCA {:>3} components + whitening'.format(50))\n",
    "print('Train Accuracy\\t\\tValidation Accuracy')\n",
    "for row in zip(train_acc, val_acc):\n",
    "    print(\"    {:.4f}\\t\\t\\t{:.4f}\".format(row[0], row[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
