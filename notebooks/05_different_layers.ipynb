{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensitivity study- using different layers than fc1\n",
    "====\n",
    "How will our choice of output layer in VGG16 affect the classification performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module imports and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'../')\n",
    "from helper import (classification_tools as ct,\n",
    "                   visualize as vis)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### list of accuracies for final boxplot\n",
    "features_root = Path('..','data','features')\n",
    "assert features_root.is_dir()\n",
    "features_all = [] # list of feature names\n",
    "accs_all = [] # list of list of all accuracies for each feature \n",
    "inertias_all = [] # list of points corresponding to accuracy of clustering with minimum inertia for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_path = Path('..','models','label_encoder.pickle')\n",
    "assert le_path.is_file()\n",
    "with open(le_path, 'rb') as f:\n",
    "    le = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering with different layers\n",
    "We will follow a similar approach for each feature:\n",
    "  * Load the data\n",
    "  * Use PCA to see how much variance is explained by a reasonable number of components\n",
    "  * Visualize the data with t-SNE\n",
    "  * Cluster (while varying k, the number of centroids, if needed)\n",
    "  \n",
    " For many of these I had to play around with the parameters (ie number of components, cluster centers).\n",
    " \n",
    " I'm not including the results for all settings as this would get really cluttered really quick. Instead\n",
    " \n",
    " I include the results with the best performance I could find."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fc2 features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc2_path = features_root / 'VGG16_fc2_features.pickle'\n",
    "assert fc2_path.is_file()\n",
    "\n",
    "with open(fc2_path, 'rb') as f:\n",
    "    fc2_data = pickle.load(f)\n",
    "fc2_y_gt = le.transform(fc2_data['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc2_pca = PCA(n_components=50, svd_solver='full', whiten=True)\n",
    "fc2_pca_nw = PCA(n_components=50, svd_solver='full', whiten=False)\n",
    "\n",
    "\n",
    "fc2_pca_n = PCA(svd_solver='full', whiten='False')\n",
    "fc2_pca_n.fit(fc2_data['features'])\n",
    "\n",
    "fc2_var = (fc2_pca_n.explained_variance_ratio_[:100]).cumsum()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,3), dpi=150)\n",
    "ax.set_xlabel('number of PCA components')\n",
    "ax.set_ylabel('fraction of variance explained')\n",
    "ax.set_title(fc2_data['layer_name'])\n",
    "ax.plot(range(1, len(fc2_var)+1), fc2_var, '-k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc2_x_nw = fc2_pca_nw.fit_transform(fc2_data['features'])\n",
    "fc2_x = fc2_pca.fit_transform(fc2_data['features'])\n",
    "\n",
    "\n",
    "\n",
    "fc2_tsne = TSNE(n_components=2, random_state=12213)\n",
    "fc2_x_tsne = fc2_tsne.fit_transform(fc2_x_nw)\n",
    "fig, ax = plt.subplots()\n",
    "sns.scatterplot(fc2_x_tsne[:,0], fc2_x_tsne[:,1], hue=fc2_data['labels'], hue_order=le.labels_ordered)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc2_cache_path = Path('..','.neu_cache','fc2_features.pickle')\n",
    "use_cache=True\n",
    "if not use_cache or not fc2_cache_path.is_file():    \n",
    "    fc2_kmeans = KMeans(n_clusters=7, init='k-means++', \n",
    "                    n_init=500, random_state=634494157)\n",
    "    fc2_kmeans.fit(fc2_x)\n",
    "    fc2_labels_unmatched = fc2_kmeans.labels_\n",
    "    fc2_y_pred = ct.label_matcher(fc2_labels_unmatched, fc2_y_gt)\n",
    "    fc2_CM = confusion_matrix(fc2_y_gt, fc2_y_pred)\n",
    "    fc2_acc = fc2_CM.trace()/fc2_CM.sum()\n",
    "    with open(fc2_cache_path, 'wb') as f:\n",
    "        pickle.dump((fc2_acc, fc2_CM),f)\n",
    "else:\n",
    "    with open(fc2_cache_path, 'rb') as f:\n",
    "        fc2_acc, fc2_CM = pickle.load(f)\n",
    "fig, ax = plt.subplots(figsize=(3,3), dpi=150)\n",
    "vis.pretty_cm(fc2_CM, labelnames=le.labels_ordered, ax0=ax, fs=7, cmap='cool')\n",
    "plt.show()\n",
    "\n",
    "print('accuracy: {:.3f}'.format(fc2_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "block5_pool features\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b5p_path = features_root / 'VGG16_block5_pool_features.pickle'\n",
    "assert b5p_path.is_file()\n",
    "\n",
    "with open(b5p_path, 'rb') as f:\n",
    "    b5p_data = pickle.load(f)\n",
    "b5p_y_gt = le.transform(b5p_data['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b5p_pca = PCA(n_components=110, svd_solver='full', whiten=True)\n",
    "b5p_pca_nw = PCA(n_components=110, svd_solver='full', whiten=False)\n",
    "\n",
    "b5p_features_reshape = b5p_data['features'].reshape(len(b5p_data['features']),-1)\n",
    "b5p_pca_n = PCA(svd_solver='full', whiten='False')\n",
    "b5p_pca_n.fit(b5p_features_reshape)\n",
    "\n",
    "b5p_var = (b5p_pca_n.explained_variance_ratio_[:1000]).cumsum()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,3), dpi=150)\n",
    "ax.set_xlabel('number of PCA components')\n",
    "ax.set_ylabel('fraction of variance explained')\n",
    "ax.set_title(b5p_data['layer_name'])\n",
    "ax.plot(range(1, len(b5p_var)+1), b5p_var, '-k')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b5p_x_nw = b5p_pca_nw.fit_transform(b5p_features_reshape)\n",
    "b5p_x = b5p_pca.fit_transform(b5p_features_reshape)\n",
    "\n",
    "\n",
    "b5p_tsne = TSNE(n_components=2, random_state=12213)\n",
    "b5p_x_tsne = b5p_tsne.fit_transform(b5p_x_nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3,2), dpi=300, facecolor='w')\n",
    "sns.scatterplot(b5p_x_tsne[:,0], b5p_x_tsne[:,1], hue=b5p_data['labels'], hue_order=le.labels_ordered, ax=ax)\n",
    "#ax.axis('off')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "l1 = ax.legend(loc='upper center', ncol=1,\n",
    "                bbox_to_anchor=(1.25,1), columnspacing=0.5, fontsize=(8), handletextpad=0.5)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(Path('..','Figures','b5p_tsne.png'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b5p_tsne_kmeans_cache_path = Path('..','.neu_cache','b5p_kmeans_tsne.pickle')\n",
    "use_cache=True\n",
    "\n",
    "if not use_cache or not b5p_tsne_kmeans_cache_path.is_file():\n",
    "    rs_ = np.random.RandomState(3081759952)\n",
    "    k_values_ = list(range(6,25))\n",
    "    tsne_cms = []\n",
    "    for k, state in zip(k_values_, rs_.randint(2**32, size=len(k_values_))):\n",
    "        b5p_kmeans_tsne = KMeans(n_clusters=k, init='k-means++', n_init=500, random_state=state)\n",
    "        b5p_kmeans_tsne.fit(b5p_x_tsne)\n",
    "        b5p_tsne_y_pred = ct.label_matcher(b5p_kmeans_tsne.labels_, b5p_y_gt)\n",
    "        b5p_tsne_cm = confusion_matrix(b5p_y_gt, b5p_tsne_y_pred)\n",
    "        print(b5p_tsne_cm)\n",
    "        tsne_cms.append(b5p_tsne_cm)\n",
    "    with open(b5p_tsne_kmeans_cache_path, 'wb') as f:\n",
    "        pickle.dump([k_values_, tsne_cms], f)\n",
    "else:\n",
    "    with open(b5p_tsne_kmeans_cache_path, 'rb') as f:\n",
    "        k_values_, tsne_cms = pickle.load(f)\n",
    "for k, cm in zip(k_values_, tsne_cms):\n",
    "    print('k: {:>2}\\tacc: {:.3f}'.format(k, cm.trace()/cm.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3,3), dpi=300)\n",
    "vis.pretty_cm(tsne_cms[-2], le.labels_ordered, ax0=ax, fs=8, cmap='cool')\n",
    "fig.tight_layout()\n",
    "fig.savefig(Path('..','Figures','b5p_cm.png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b5p_cache_path = Path('..','.neu_cache','b5p_features_k.pickle')\n",
    "use_cache=True\n",
    "\n",
    "if not use_cache or not b5p_cache_path.is_file():\n",
    "    b5p_klist = list(range(6,20))\n",
    "    b5p_CMlist=[]\n",
    "    rs = np.random.RandomState(seed=2296093342)\n",
    "    for k, state in zip(b5p_klist, rs.randint(2**32, size=len(b5p_klist))):\n",
    "        b5p_kmeans = KMeans(n_clusters=k, init='k-means++', \n",
    "                        n_init=500, random_state=state)\n",
    "        b5p_kmeans.fit(b5p_x)\n",
    "        b5p_labels_unmatched = b5p_kmeans.labels_\n",
    "        b5p_y_pred = ct.label_matcher(b5p_labels_unmatched, b5p_y_gt)\n",
    "        b5p_CM = confusion_matrix(b5p_y_gt, b5p_y_pred)\n",
    "        b5p_CMlist.append(b5p_CM)\n",
    "    with open(b5p_cache_path, 'wb') as f:\n",
    "        pickle.dump((b5p_klist, b5p_CMlist), f)\n",
    "else:\n",
    "    with open(b5p_cache_path, 'rb') as f:\n",
    "        b5p_klist, b5p_CMlist = pickle.load(f)\n",
    "for ki, cmi in zip(b5p_klist, b5p_CMlist):\n",
    "    print('k: {:>2} \\taccuracy: {:.3f}'.format(ki, cmi.trace()/cmi.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3,3), dpi=150)\n",
    "vis.pretty_cm(b5p_CMlist[3], le.labels_ordered, cmap='cool', ax0=ax, fs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b5p_gt, b5p_pred = ct.deconstruct_cm(b5p_CMlist[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ct.latex_report(b5p_gt, b5p_pred, le.labels_ordered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconstruct_cm(cm):\n",
    "    \"\"\"\n",
    "    Turns 2d confusion matrix into 2 1d arrays of ground truth values and predicted values.\n",
    "    \n",
    "    The cache saves confusion matrices instead of the actual predictions, but it is more\n",
    "    convenient to have predictions for the classification report. Note that the order of\n",
    "    files is not preserved.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    cm: ndarray\n",
    "        n_class x n_class array of ints corresponding to the number of predictions for each\n",
    "        class.\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    gt, pred: ndarray\n",
    "        n_class element array of integer ground truth (gt) or predicted (pred) labels\n",
    "        \n",
    "    \n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    \n",
    "    cm = np.asarray([[1,2],[3,4]])\n",
    "    gt, pred = deconstruct_cm(cm)\n",
    "    print(gt)\n",
    "    >>> [0 0 0 1 1 1 1 1 1 1]\n",
    "    print(pred)\n",
    "    >>> [0 1 1 0 0 0 1 1 1 1]\n",
    "    \"\"\"\n",
    "    r, c = cm.shape\n",
    "    assert r == c\n",
    "    gt = []\n",
    "    pred = []\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            for _ in range(cm[i,j]):\n",
    "                gt.append(i)\n",
    "                pred.append(j)\n",
    "    gt = np.asarray(gt)\n",
    "    pred = np.asarray(pred)\n",
    "    return gt, pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "block5 conv3 features\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b5c3_path = features_root / 'VGG16_block5_conv3_features.pickle'\n",
    "assert b5c3_path.is_file()\n",
    "\n",
    "with open(b5c3_path, 'rb') as f:\n",
    "    b5c3_data = pickle.load(f)\n",
    "b5c3_y_gt = le.transform(b5c3_data['labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b5c3_data['features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b5c3_pca = PCA(n_components=200, svd_solver='full', whiten=True)\n",
    "b5c3_pca_nw = PCA(n_components=200, svd_solver='full', whiten=False)\n",
    "\n",
    "b5c3_features_reshape = b5c3_data['features'].reshape(len(b5c3_data['features']),-1)\n",
    "b5c3_pca_n = PCA(svd_solver='full', whiten='False')\n",
    "b5c3_pca_n.fit(b5c3_features_reshape)\n",
    "\n",
    "b5c3_var = (b5c3_pca_n.explained_variance_ratio_[:1000]).cumsum()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,3), dpi=150)\n",
    "ax.set_xlabel('number of PCA components')\n",
    "ax.set_ylabel('fraction of variance explained')\n",
    "ax.set_title(b5c3_data['layer_name'])\n",
    "ax.plot(range(1, len(b5c3_var)+1), b5c3_var, '-k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b5c3_x_nw = b5c3_pca_nw.fit_transform(b5c3_features_reshape)\n",
    "b5c3_x = b5c3_pca.fit_transform(b5c3_features_reshape)\n",
    "\n",
    "\n",
    "b5c3_tsne = TSNE(n_components=2, random_state=12213)\n",
    "b5c3_x_tsne = b5c3_tsne.fit_transform(b5c3_x_nw)\n",
    "fig, ax = plt.subplots()\n",
    "sns.scatterplot(b5c3_x_tsne[:,0], b5c3_x_tsne[:,1], hue=b5c3_data['labels'], hue_order=le.labels_ordered)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b5c3_cache_path = Path('..','.neu_cache','b5c3_features_k.pickle')\n",
    "use_cache=True\n",
    "\n",
    "if not use_cache or not b5c3_cache_path.is_file():\n",
    "    b5c3_klist = list(range(6,20))\n",
    "    b5c3_CMlist=[]\n",
    "    rs = np.random.RandomState(seed=1531754964)\n",
    "    for k, state in zip(b5c3_klist, rs.randint(2**32, size=len(b5c3_klist))):\n",
    "        b5c3_kmeans = KMeans(n_clusters=k, init='k-means++', \n",
    "                        n_init=500, random_state=state)\n",
    "        b5c3_kmeans.fit(b5c3_x)\n",
    "        b5c3_labels_unmatched = b5c3_kmeans.labels_\n",
    "        b5c3_y_pred = ct.label_matcher(b5c3_labels_unmatched, b5c3_y_gt)\n",
    "        b5c3_CM = confusion_matrix(b5c3_y_gt, b5c3_y_pred)\n",
    "        b5c3_CMlist.append(b5c3_CM)\n",
    "    with open(b5c3_cache_path, 'wb') as f:\n",
    "        pickle.dump((b5c3_klist, b5c3_CMlist), f)\n",
    "else:\n",
    "    with open(b5c3_cache_path, 'rb') as f:\n",
    "        b5c3_klist, b5c3_CMlist = pickle.load(f)\n",
    "for ki, cmi in zip(b5c3_klist, b5c3_CMlist):\n",
    "    print('k: {:>2} \\taccuracy: {:.3f}'.format(ki, cmi.trace()/cmi.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3,3), dpi=150)\n",
    "vis.pretty_cm(b5c3_CMlist[-2], le.labels_ordered, cmap='cool', ax0=ax, fs=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
