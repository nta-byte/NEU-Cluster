{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Analysis\n",
    "\n",
    "This is the baseline approach to classifying the images. \n",
    "\n",
    "The sensitivity analysis conducted in the other notebooks will change individual steps in this analysis.\n",
    "\n",
    "The techniques are described in the paper, so this notebook will focus more on implementation than explaning the approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module imports\n",
    "\n",
    "We will use sklearn for the machine learning algorithms. Pandas provides a convenient way to organize\n",
    "\n",
    "data and will help with plotting later. Matplotlib and seaborn are used to actually visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "import skimage.io\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'../')\n",
    "from helper import classification_tools as ct\n",
    "from helper import visualize as vis\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "We already have the file paths, features, and labels from the last step, so we just need to retrieve it from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fc1 features saved from the previous step\n",
    "fc1_path = Path('..','data','features','VGG16_fc1_features_std.pickle')\n",
    "assert fc1_path.is_file()\n",
    "\n",
    "# label encoder model which converts string labels to integers.\n",
    "le_path = Path('..','models','label_encoder.pickle')\n",
    "assert le_path.is_file()\n",
    "\n",
    "# load the data and label encoder into memory\n",
    "with open(fc1_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "with open(le_path, 'rb') as f:\n",
    "    le = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = data['filename']  # file paths to each image\n",
    "fc1 = data['features']  # array containing fc1 features for each file\n",
    "labels = data['labels']  # string labels for each image\n",
    "y_gt = le.transform(labels)  # integer labels for each image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have everything we need to do the analysis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension reduction\n",
    "### PCA\n",
    "The first step in the analys is PCA, which will reduce the dimensionality of the data and hopefully filter out noise.\n",
    "\n",
    "The question is- how many dimensions to keep?\n",
    "\n",
    "There is no right answer, but we want to keep components that contain signal (ie significant variance) and get rid of ones\n",
    "\n",
    "that are mostly noise. For high dimensional data, like our fc1 features, a rule of thumb is to select 50 components. Before blindly\n",
    "\n",
    "selecting 50, we will see how much variance each component preserves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_n = PCA(svd_solver='full')\n",
    "x_pca_ = pca_n.fit_transform(fc1)\n",
    "\n",
    "var_ = pca_n.explained_variance_ratio_.cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was easy! Let's view the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,2),dpi=150,)\n",
    "ax.grid('on', which='both', color=np.ones(3)*0.85)\n",
    "ax.plot(range(1,len(var_)+1), var_, color='darkviolet')\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('number of components')\n",
    "ax.set_ylabel('fraction of\\nvariance explained')\n",
    "\n",
    "yt=np.linspace(1/4, 1, 4)\n",
    "ytm = [np.mean([yt[i], yt[i+1]]) for i in range(len(yt)-1)]\n",
    "ax.set_yticks(ytm, minor=True)\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(Path('..','Figures','PCA_Var.png'), bbox_inches='tight')\n",
    "print('variance preserved by 50 components: {:.3f}'.format(var_[50]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50 components preserves  73.6% of the variance, so it seems to be a reasonable starting point for this task.\n",
    "\n",
    "Let's proceed to extract 50 components. We will also look at a setting called whitening, which normalizes the variance\n",
    "\n",
    "across each component after doing the decomposition. Think of this as weighting all of the components equally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-SNE Visualization\n",
    "T-SNE maps components in high-dimensional space to lower dimensions. It is commonly used to project data to 2d for visualization. \n",
    "This technique aims to preserve pairwise distances for points that are close to each other, and does not preserve distances for points that are far away from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50, svd_solver='full', whiten=True)\n",
    "pca_nw = PCA(n_components=50, svd_solver='full', whiten=False)\n",
    "x = pca.fit_transform(fc1)\n",
    "x_nw = pca_nw.fit_transform(fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=12214)\n",
    "tsne_w = TSNE(n_components=2, random_state=654753)\n",
    "x_nw_tsne = tsne.fit_transform(x_nw)\n",
    "x_w_tsne = tsne_w.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ordered = le.inverse_transform(range(len(le.mapper)))\n",
    "df = pd.DataFrame({'files': files,\n",
    "                   'x_nw':x_nw_tsne[:,0],\n",
    "                   'y_nw':x_nw_tsne[:,1],\n",
    "                   'x_w': x_w_tsne[:,0],\n",
    "                  'y_w': x_w_tsne[:,1],\n",
    "                   'labels': labels,\n",
    "                  },\n",
    "                  index=files)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(6,3), dpi=150)\n",
    "sns.scatterplot(data=df, x='x_nw', y='y_nw', hue='labels', hue_order=labels_ordered,  ax=ax[0])\n",
    "sns.scatterplot(data=df, x='x_w', y='y_w', hue='labels', hue_order=labels_ordered, ax=ax[1])\n",
    "ax[0].get_legend().remove()\n",
    "ax[1].legend(bbox_to_anchor=(1.05,1))\n",
    "ax[0].set_title('t-sne/pca\\n without whitening')\n",
    "ax[1].set_title('t-sne/pca with whitening')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The t-sne map without whitening shows much better clustering than the t-sne map with whitened components. However, as we will see, this turns out to be an artifact of t-sne, and\n",
    "\n",
    "does not represent the actual clustering of the data in feature space. Whitening normalizes the variance, and therefore pairwise distances of points in feature space, so they do not\n",
    "\n",
    "cluster in 2d as well. Despite this, we will see that they actually cluster better in feature space with whitening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also plot the images on the t-sne plot to see if we can gain any insights from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.pano_plot(x_nw_tsne[:,0], x_nw_tsne[:,1], files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how the clusters separate very well by defect class. Notice that for scratches there appear to be two different clusters.\n",
    "\n",
    "This has to do with the orientation of the scratches- one for vertical, and the other for horizontal. \n",
    "\n",
    "The vertical scratches cluster is close to the inclusions, and we can see some visual similarity between these groups. However, the horizontal scratches appear in a separate, distinct cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "Now we can cluster the data with K-means. The process is very straightforward thanks to the tools provided in skimage.\n",
    "\n",
    "The only trick is match the arbitrary cluster IDs returned from K-means to the ground truth labels they correspond to.\n",
    "\n",
    "The method I used to do this is defined in helper.classification_tools, if you want to see the implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=7, init='k-means++', n_init=500,random_state=2149673460)\n",
    "kmeans.fit(x)\n",
    "labels_unmatched = kmeans.labels_  # labels from k-means are arbitrary and must be mapped to the format of the ground truth labels\n",
    "y_pred = ct.label_matcher(labels_unmatched, y_gt,)  # this function matches the labels so we can compare directly\n",
    "print('inertia: {:.2f}'.format(kmeans.inertia_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inertia doesn't tell us much, but can be used to compare clustering results for multiple runs. \n",
    "\n",
    "This is the lowest value after 500 trials (from n_init=500)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_str = le.inverse_transform(y_pred)\n",
    "df['y_pred_labels'] = pd.Series(y_pred_str, index=files)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(8,5), dpi=150)\n",
    "\n",
    "\n",
    "sns.scatterplot(data=df, x='x_nw', y='y_nw', hue='labels', hue_order=labels_ordered, ax=ax[0]) # ground truth labels\n",
    "sns.scatterplot(data=df, x='x_nw', y='y_nw', hue='y_pred_labels', hue_order=labels_ordered, ax=ax[1]) # predicted labels\n",
    "\n",
    "ax[0].get_legend().remove()\n",
    "ax[1].legend(bbox_to_anchor=(1.05,1))\n",
    "ax[0].set_title('hue: ground truth labels')\n",
    "ax[1].set_title('hue: predicted labels')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The colors look identical, confirming we have very good clustering! They are almost exactly the same (ie we did not accidentally plot the same thing twice.) \n",
    "\n",
    "There are very slight differences around (-20,-20) with some of the scratches/inclusions being classified differently.\n",
    "\n",
    "## Confusion matrix\n",
    "This let's us visualize the classification performance with more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from helper import visualize as vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The confusion matrix allows us to evaluate the performance\n",
    "CM = confusion_matrix(y_gt, y_pred)\n",
    "vis.pretty_cm(CM, labels_ordered)\n",
    "print('Accuracy: {:.3f}'.format(CM.trace()/CM.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "99.6% accuracy, pretty good! But did we just get lucky with the random initialization of k-means, or is this process repeatable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes a couple minutes to run, be patient!\n",
    "use_cache=True\n",
    "std_10run_cache_path = Path('..','.neu_cache','st_10runresults.pickle')\n",
    "\n",
    "if not use_cache or not std_10run_cache_path.is_file():\n",
    "    rs = np.random.RandomState(seed=987654321)\n",
    "    accuracies = np.zeros(10)\n",
    "    for i, seed in enumerate(rs.randint(2**32, size=10)):\n",
    "        kmeans_ = KMeans(n_clusters=7, init='k-means++', n_init=500,random_state=seed)\n",
    "        kmeans_.fit(x)\n",
    "        labels_unmatched_ = kmeans_.labels_\n",
    "        y_pred_ = ct.label_matcher(labels_unmatched_, y_gt)\n",
    "        acc = (y_pred_ == y_gt).sum()/len(y_gt)\n",
    "        accuracies[i] = acc\n",
    "    \n",
    "    with open(std_10run_cache_path, 'wb') as f:\n",
    "        pickle.dump({'accuracies':accuracies}, f)\n",
    "else:\n",
    "    with open(std_10run_cache_path, 'rb') as f:\n",
    "        results_ = pickle.load(f)\n",
    "        accuracies = results_['accuracies']\n",
    "\n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('10 runs:\\n\\tavg: {:.4f}\\n\\tstd: {:.4},\\n\\tmin: {:.4f}'.format(accuracies.mean(), np.std(accuracies), accuracies.min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach achieves 99.4 $\\pm$ 0.16% accuracy, and all trials achieve above 99% accuracy. Pretty good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_gt, y_pred, target_names=labels_ordered, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results without whitening\n",
    "The t-sne projection showed much better clustering without whitening, yet we did clustering with whitening,\n",
    "Whitening causes t-sne to not work as well, but it actually clusters the points better in the original feature space.\n",
    "Here is what happens when we perform the same clustering approach on unwhitened pca components.\n",
    "\n",
    "We will investigate the effects of PCA more in 06_pca_num_components_whiten_nowhiten.ipynb. However, to show why we are using whitening even though the t-sne maps don't look as good, here are the clustering results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_nw = KMeans(n_clusters=7, init='k-means++', n_init=500,random_state=13)\n",
    "kmeans_nw.fit(x_nw)\n",
    "labels_unmatched_nw = kmeans_nw.labels_  # labels from k-means are arbitrary and must be mapped to the format of the ground truth labels\n",
    "y_pred_nw = ct.label_matcher(labels_unmatched_nw, y_gt,)  # this function matches the labels so we can compare directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_nw = confusion_matrix(y_gt, y_pred_nw)\n",
    "vis.pretty_cm(cm_nw, labelnames=labels_ordered)\n",
    "\n",
    "print(classification_report(y_gt, y_pred_nw, target_names=labels_ordered, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering still achieves 96% accuracy, but not nearly as good. Whitening helps boost the signal in feature space. This isn't captured by t-sne because information is always lost when projecting down from 50 to 2 dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures\n",
    "At this point this part of the analysis is done, I just need to finish generating figures for the paper!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-sne figure illustrating 2 scratch clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the t-sne plot, the two Sc clusters can separate based on their y-value \n",
    "# y = -10 perfectly separates the clusters\n",
    "\n",
    "Sc_label = le.transform(['Sc'])[0]\n",
    "Scgroup1 = np.logical_and(x_nw_tsne[:,1] < -10, \n",
    "                          y_gt==Sc_label)\n",
    "Scgroup2 = np.logical_and(x_nw_tsne[:,1] > -10, \n",
    "                          y_gt==Sc_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the 'most typical' image from each cluster, we can select the\n",
    "# point that is closest to the cluster centroid\n",
    "\n",
    "x1_Sc1 = x_nw_tsne[Scgroup1]\n",
    "x1_Sc2 = x_nw_tsne[Scgroup2]\n",
    "\n",
    "i1 = cdist(x1_Sc1, \n",
    "        np.mean(x1_Sc1, axis=0)[np.newaxis, :]).argmin()\n",
    "i2 = cdist(x1_Sc2, \n",
    "        np.mean(x1_Sc2, axis=0)[np.newaxis, :]).argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labarray = np.asarray(labels)\n",
    "filearray = np.asarray(files)\n",
    "\n",
    "group1files = filearray[Scgroup1]\n",
    "group2files = filearray[Scgroup2]\n",
    "\n",
    "file1 = group1files[i1]\n",
    "file2 = group2files[i2]\n",
    "\n",
    "im1 = skimage.io.imread(file1)\n",
    "im2 = skimage.io.imread(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax  = plt.subplots(figsize=(3,2), dpi=300, facecolor='w')\n",
    "sns.scatterplot(x_nw_tsne[:,0], x_nw_tsne[:,1], \n",
    "                 hue=labels, hue_order=le.labels_ordered, ax=ax)\n",
    "ax.axis([-85,70,-55,55])\n",
    "l1 = ax.legend(loc='upper center', ncol=1,\n",
    "                bbox_to_anchor=(1.2,1), columnspacing=0.5, fontsize=(8), handletextpad=0.5)\n",
    "\n",
    "ia1 = ax.inset_axes([0.005,0.1,0.25,0.25])\n",
    "ia1.set_xticks([])\n",
    "ia1.set_yticks([])\n",
    "ia1.axis([0,1,0,1])\n",
    "ia1.imshow(im1, cmap='gray', extent=(0,1,0,1))\n",
    "\n",
    "ia2 = ax.inset_axes([0.005,0.65,0.25,0.25])\n",
    "ia2.axis([0,1,0,1])\n",
    "ia2.set_xticks([])\n",
    "ia2.set_yticks([])\n",
    "ia2.imshow(im2, extent=(0,1,0,1), cmap='gray')\n",
    "# ax.plot(x1_Sc1[i1,0], x1_Sc1[i1,1], 'kd')\n",
    "# ax.plot(x1_Sc2[i2,0], x1_Sc2[i2,1], 'ks')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "#fig.tight_layout()\n",
    "\n",
    "fig_path = Path('..','Figures')\n",
    "fig.savefig(fig_path / 'tsne_scratches_inlay.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4,3), dpi=300)\n",
    "gs = gridspec.GridSpec(nrows=2, ncols=2, hspace=0.25)\n",
    "ax1 = fig.add_subplot(gs[0,:])\n",
    "ax2 = fig.add_subplot(gs[1,0])\n",
    "ax3 = fig.add_subplot(gs[1,1])\n",
    "sns.scatterplot(x_nw_tsne[:,0], x_nw_tsne[:,1], \n",
    "                 hue=labels, hue_order=le.labels_ordered, ax=ax1)\n",
    "l1 = ax1.legend(loc='upper center', ncol=6,\n",
    "                bbox_to_anchor=(0.55,1.3), columnspacing=0.5, fontsize=(8), handletextpad=0.5)\n",
    "\n",
    "ax1.plot(x1_Sc1[i1,0], x1_Sc1[i1,1], 'kd')\n",
    "ax1.plot(x1_Sc2[i2,0], x1_Sc2[i2,1], 'ks')\n",
    "\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "\n",
    "\n",
    "ax2.imshow(im1, cmap='gray', extent=(0,1,0,1))\n",
    "ax3.imshow(im2, cmap='gray', extent=(0,1,0,1))\n",
    "\n",
    "bb = ax1.get_position()\n",
    "ax2.set_position((0.125, *ax2.get_position().bounds[1:]))\n",
    "\n",
    "ax2.axis('off')\n",
    "ax3.axis('off')\n",
    "\n",
    "\n",
    "ax1.set_title('a)', loc='left', fontsize=10)\n",
    "ax2.set_title('b)', loc='left', fontsize=10)\n",
    "ax3.set_title('c)', loc='left', fontsize=10)\n",
    "#fig.tight_layout()\n",
    "fig_path = Path('..','Figures')\n",
    "fig.savefig(fig_path / 'tsne_scratches.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE figure with labels colored by k-means labels from standard analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results determined using one of the trials from the 10 repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1844281023\n",
    "kmeans_ = KMeans(n_clusters=7, init='k-means++', n_init=500,random_state=seed)\n",
    "kmeans_.fit(x)\n",
    "labels_unmatched_ = kmeans_.labels_\n",
    "y_pred_ = ct.label_matcher(labels_unmatched_, y_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strlabels = ct.label_matcher_multicluster(kmeans_.labels_, y_gt, le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.concatenate((sns.color_palette()[:5], sns.color_palette()[5:6], sns.color_palette('bright')[5:6]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax  = plt.subplots(figsize=(3,2), dpi=300, facecolor='w')\n",
    "sns.scatterplot(x_nw_tsne[:,0], x_nw_tsne[:,1], \n",
    "                 hue=strlabels, hue_order=sorted(np.unique(strlabels), key=lambda x: x.upper()), ax=ax, palette=list(colors))\n",
    "ax.axis([-75,70,-55,55])\n",
    "l1 = ax.legend(loc='upper center', ncol=1,\n",
    "                bbox_to_anchor=(1.25,1), columnspacing=0.5, fontsize=(8), handletextpad=0.5)\n",
    "\n",
    "\n",
    "# ax.plot(x1_Sc1[i1,0], x1_Sc1[i1,1], 'kd')\n",
    "# ax.plot(x1_Sc2[i2,0], x1_Sc2[i2,1], 'ks')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "fig.tight_layout()\n",
    "\n",
    "fig_path = Path('..','Figures')\n",
    "fig.savefig(fig_path / 'tsne_kmeans_labels_std.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intlabels = ct.label_matcher(kmeans.labels_, y_gt)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3,3), dpi=300)\n",
    "CM = confusion_matrix(y_gt, intlabels)\n",
    "vis.pretty_cm(CM, labelnames=le.labels_ordered, ax0=ax, fs=8, cmap='cool', )\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(fig_path / 'CM_std.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "print('accuracy: {}'.format(CM.trace()/CM.sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from helper import classification_tools as ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ct.latex_report(y_gt, intlabels, le.labels_ordered))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
